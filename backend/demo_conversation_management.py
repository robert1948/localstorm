"""
Advanced Conversation Management System Validation Demo
Comprehensive testing and validation of the conversation management system

Author: CapeAI Development Team
Date: July 25, 2025
"""

import asyncio
import json
import time
import sys
import traceback
from datetime import datetime, timedelta
from typing import Dict, List, Any

# Add the app directory to the path for imports
sys.path.insert(0, '/home/robert/Documents/localstorm250722/backend')

try:
    from app.services.conversation_manager import (
        ConversationManager,
        EnhancedConversation,
        ConversationMessage,
        ConversationThread,
        ConversationSummary,
        ConversationAnalytics,
        MessageRole,
        ConversationType,
        ConversationStatus,
        ThreadingStrategy,
        create_conversation_manager
    )
    print("‚úÖ Successfully imported conversation management components")
except ImportError as e:
    print(f"‚ùå Import error: {e}")
    print("Checking available modules...")
    import os
    app_path = '/home/robert/Documents/localstorm250722/backend/app'
    if os.path.exists(app_path):
        print(f"App directory exists: {app_path}")
        services_path = os.path.join(app_path, 'services')
        if os.path.exists(services_path):
            print(f"Services directory exists: {services_path}")
            files = os.listdir(services_path)
            print(f"Files in services: {files}")
        else:
            print("Services directory does not exist")
    else:
        print("App directory does not exist")
    sys.exit(1)

class ConversationValidationDemo:
    """Comprehensive validation demo for conversation management system"""
    
    def __init__(self):
        """Initialize the validation demo"""
        self.results = {
            'tests_run': 0,
            'tests_passed': 0,
            'tests_failed': 0,
            'errors': [],
            'performance_metrics': {},
            'functional_tests': {},
            'integration_tests': {}
        }
        
        # Configuration for the conversation manager
        self.config = {
            'auto_threading_enabled': True,
            'default_threading_strategy': 'hybrid',
            'max_context_messages': 50,
            'auto_summary_threshold': 20
        }
        
        print("üöÄ Advanced Conversation Management System Validation Demo")
        print("=" * 60)
    
    async def run_validation(self):
        """Run complete validation suite"""
        try:
            print("\nüìã Starting comprehensive validation...")
            
            # 1. Basic component validation
            await self._test_basic_components()
            
            # 2. Conversation management validation
            await self._test_conversation_management()
            
            # 3. Message handling validation
            await self._test_message_handling()
            
            # 4. Threading system validation
            await self._test_threading_system()
            
            # 5. Search and analytics validation
            await self._test_search_and_analytics()
            
            # 6. Performance validation
            await self._test_performance()
            
            # 7. Integration scenarios
            await self._test_integration_scenarios()
            
            # 8. Error handling validation
            await self._test_error_handling()
            
            # Generate final report
            self._generate_report()
            
        except Exception as e:
            self.results['errors'].append(f"Critical validation error: {str(e)}")
            print(f"‚ùå Critical error during validation: {e}")
            traceback.print_exc()
    
    async def _test_basic_components(self):
        """Test basic component creation and functionality"""
        print("\nüîß Testing Basic Components...")
        
        try:
            # Test ConversationMessage creation
            test_name = "ConversationMessage Creation"
            self._start_test(test_name)
            
            message = ConversationMessage(
                message_id="test_msg_001",
                conversation_id="test_conv_001",
                role=MessageRole.USER,
                content="Test message for validation",
                timestamp=datetime.utcnow(),
                tokens=10
            )
            
            assert message.message_id == "test_msg_001"
            assert message.role == MessageRole.USER
            assert message.content == "Test message for validation"
            assert message.tokens == 10
            
            # Test message to_dict conversion
            message_dict = message.to_dict()
            assert isinstance(message_dict, dict)
            assert message_dict['message_id'] == "test_msg_001"
            assert message_dict['role'] == 'user'
            
            self._pass_test(test_name)
            
            # Test ConversationThread creation
            test_name = "ConversationThread Creation"
            self._start_test(test_name)
            
            thread = ConversationThread(
                thread_id="test_thread_001",
                conversation_id="test_conv_001",
                title="Test Thread",
                description="A test thread for validation"
            )
            
            assert thread.thread_id == "test_thread_001"
            assert thread.title == "Test Thread"
            assert thread.message_count == 0
            assert thread.status == "active"
            
            # Test thread to_dict conversion
            thread_dict = thread.to_dict()
            assert isinstance(thread_dict, dict)
            assert thread_dict['thread_id'] == "test_thread_001"
            
            self._pass_test(test_name)
            
            # Test EnhancedConversation creation
            test_name = "EnhancedConversation Creation"
            self._start_test(test_name)
            
            conversation = EnhancedConversation(
                conversation_id="test_conv_001",
                user_id="test_user_001",
                conversation_data={
                    "title": "Test Conversation",
                    "description": "A conversation for validation testing",
                    "conversation_type": "technical",
                    "auto_threading": True,
                    "threading_strategy": "hybrid"
                }
            )
            
            assert conversation.conversation_id == "test_conv_001"
            assert conversation.user_id == "test_user_001"
            assert conversation.title == "Test Conversation"
            assert conversation.conversation_type == ConversationType.TECHNICAL
            assert conversation.auto_threading is True
            assert conversation.threading_strategy == ThreadingStrategy.HYBRID
            
            self._pass_test(test_name)
            
        except Exception as e:
            self._fail_test(test_name if 'test_name' in locals() else "Basic Components", str(e))
    
    async def _test_conversation_management(self):
        """Test conversation manager functionality"""
        print("\nüí¨ Testing Conversation Management...")
        
        try:
            # Create conversation manager
            test_name = "ConversationManager Creation"
            self._start_test(test_name)
            
            manager = create_conversation_manager(self.config)
            assert manager is not None
            assert isinstance(manager, ConversationManager)
            
            self._pass_test(test_name)
            
            # Test conversation creation
            test_name = "Conversation Creation via Manager"
            self._start_test(test_name)
            
            conversation_data = {
                "title": "Machine Learning Discussion",
                "description": "Discussing ML algorithms and implementations",
                "conversation_type": "technical",
                "tags": ["ml", "python", "algorithms"],
                "auto_threading": True,
                "threading_strategy": "hybrid"
            }
            
            conversation = await manager.create_conversation("user_test_001", conversation_data)
            
            assert conversation is not None
            assert conversation.user_id == "user_test_001"
            assert conversation.title == "Machine Learning Discussion"
            assert conversation.conversation_type == ConversationType.TECHNICAL
            assert "ml" in conversation.tags
            
            # Verify manager state
            assert conversation.conversation_id in manager.conversations
            assert "user_test_001" in manager.user_conversations
            assert manager.performance_metrics["total_conversations"] == 1
            
            self._pass_test(test_name)
            
            # Test conversation retrieval
            test_name = "Conversation Retrieval"
            self._start_test(test_name)
            
            retrieved_conv = await manager.get_conversation(conversation.conversation_id)
            assert retrieved_conv is not None
            assert retrieved_conv.conversation_id == conversation.conversation_id
            assert retrieved_conv.title == conversation.title
            
            self._pass_test(test_name)
            
            # Test user conversations listing
            test_name = "User Conversations Listing"
            self._start_test(test_name)
            
            user_conversations = await manager.get_user_conversations("user_test_001")
            assert len(user_conversations) == 1
            assert user_conversations[0].conversation_id == conversation.conversation_id
            
            self._pass_test(test_name)
            
            # Store for later tests
            self.test_manager = manager
            self.test_conversation = conversation
            
        except Exception as e:
            self._fail_test(test_name if 'test_name' in locals() else "Conversation Management", str(e))
    
    async def _test_message_handling(self):
        """Test message handling functionality"""
        print("\nüìù Testing Message Handling...")
        
        try:
            manager = self.test_manager
            conversation = self.test_conversation
            
            # Test adding messages
            test_name = "Message Addition"
            self._start_test(test_name)
            
            messages_to_add = [
                (MessageRole.USER, "I'm interested in learning about neural networks. Where should I start?"),
                (MessageRole.ASSISTANT, "Great question! Neural networks are a fascinating topic. I'd recommend starting with the basics of perceptrons and then moving to multi-layer networks."),
                (MessageRole.USER, "What programming languages are best for implementing neural networks?"),
                (MessageRole.ASSISTANT, "Python is the most popular choice due to libraries like TensorFlow, PyTorch, and Keras. R and Julia are also good options for research."),
                (MessageRole.USER, "Can you explain backpropagation in simple terms?"),
                (MessageRole.ASSISTANT, "Backpropagation is the process of updating network weights by calculating the gradient of the loss function and propagating errors backward through the network.")
            ]
            
            added_messages = []
            for role, content in messages_to_add:
                message = await manager.add_message(conversation.conversation_id, role, content)
                assert message is not None
                assert message.role == role
                assert message.content == content
                added_messages.append(message)
            
            # Verify conversation state
            updated_conversation = await manager.get_conversation(conversation.conversation_id)
            assert len(updated_conversation.messages) == 6
            assert manager.performance_metrics["total_messages"] == 6
            
            self._pass_test(test_name)
            
            # Test message editing
            test_name = "Message Editing"
            self._start_test(test_name)
            
            first_message = added_messages[0]
            original_content = first_message.content
            new_content = "I'm very interested in learning about neural networks and deep learning. Where should I start?"
            
            success = await updated_conversation.edit_message(first_message.message_id, new_content)
            assert success is True
            
            # Verify edit
            edited_message = updated_conversation.message_index[first_message.message_id]
            assert edited_message.content == new_content
            assert edited_message.edited is True
            assert len(edited_message.edit_history) == 1
            assert edited_message.edit_history[0]["previous_content"] == original_content
            
            self._pass_test(test_name)
            
            # Test message search
            test_name = "Message Search"
            self._start_test(test_name)
            
            # Search for "neural networks"
            search_results = await updated_conversation.search_messages("neural networks")
            assert len(search_results) >= 2  # Should find multiple mentions
            
            # Search for "Python"
            python_results = await updated_conversation.search_messages("Python")
            assert len(python_results) >= 1
            
            # Search with role filter
            user_messages = await updated_conversation.search_messages("neural", {"role": "user"})
            assert len(user_messages) >= 1
            assert all(msg.role == MessageRole.USER for msg in user_messages)
            
            self._pass_test(test_name)
            
            # Store updated conversation
            self.test_conversation = updated_conversation
            
        except Exception as e:
            self._fail_test(test_name if 'test_name' in locals() else "Message Handling", str(e))
    
    async def _test_threading_system(self):
        """Test conversation threading system"""
        print("\nüßµ Testing Threading System...")
        
        try:
            conversation = self.test_conversation
            
            # Test manual thread creation
            test_name = "Manual Thread Creation"
            self._start_test(test_name)
            
            # Get first 4 messages for threading
            message_ids = [msg.message_id for msg in conversation.messages[:4]]
            
            thread = await conversation.create_thread(
                "Neural Networks Basics",
                message_ids,
                "educational"
            )
            
            assert thread is not None
            assert thread.title == "Neural Networks Basics"
            assert thread.thread_type == "educational"
            assert thread.message_count == 4
            assert len(conversation.threads) == 1
            
            # Verify messages are assigned to thread
            threaded_messages = [msg for msg in conversation.messages if msg.thread_id == thread.thread_id]
            assert len(threaded_messages) == 4
            
            self._pass_test(test_name)
            
            # Test thread message retrieval
            test_name = "Thread Message Retrieval"
            self._start_test(test_name)
            
            thread_messages = await conversation.get_thread_messages(thread.thread_id)
            assert len(thread_messages) == 4
            assert all(msg.thread_id == thread.thread_id for msg in thread_messages)
            
            self._pass_test(test_name)
            
            # Test auto-threading (add more messages)
            test_name = "Auto-Threading"
            self._start_test(test_name)
            
            # Add messages that should trigger auto-threading
            auto_messages = [
                (MessageRole.USER, "What about convolutional neural networks for image processing?"),
                (MessageRole.ASSISTANT, "CNNs are excellent for image tasks. They use filters to detect features like edges and patterns."),
                (MessageRole.USER, "How do I choose the right optimizer for training?"),
                (MessageRole.ASSISTANT, "Adam is a good default choice, but SGD with momentum can work better for some problems.")
            ]
            
            for role, content in auto_messages:
                await conversation.add_message(role, content)
            
            # Check if auto-threading occurred
            updated_conversation = await self.test_manager.get_conversation(conversation.conversation_id)
            
            # Auto-threading may or may not create new threads depending on content similarity
            # Just verify the messages were added successfully
            assert len(updated_conversation.messages) == 10  # 6 original + 4 new
            
            self._pass_test(test_name)
            
            # Test thread merging (create second thread first)
            test_name = "Thread Merging"
            self._start_test(test_name)
            
            # Create second thread with remaining messages
            remaining_message_ids = [msg.message_id for msg in updated_conversation.messages[6:8]]
            thread2 = await updated_conversation.create_thread(
                "Advanced Neural Networks",
                remaining_message_ids,
                "advanced"
            )
            
            assert len(updated_conversation.threads) == 2
            
            # Merge threads
            success = await updated_conversation.merge_threads(thread2.thread_id, thread.thread_id)
            assert success is True
            assert len(updated_conversation.threads) == 1
            
            # Verify merged thread has more messages
            remaining_thread = list(updated_conversation.threads.values())[0]
            assert remaining_thread.message_count == 6  # 4 original + 2 merged
            
            self._pass_test(test_name)
            
            # Store updated conversation
            self.test_conversation = updated_conversation
            
        except Exception as e:
            self._fail_test(test_name if 'test_name' in locals() else "Threading System", str(e))
    
    async def _test_search_and_analytics(self):
        """Test search functionality and analytics generation"""
        print("\nüîç Testing Search and Analytics...")
        
        try:
            manager = self.test_manager
            conversation = self.test_conversation
            
            # Test conversation search
            test_name = "Conversation Search"
            self._start_test(test_name)
            
            search_results = await manager.search_conversations("user_test_001", "machine learning")
            assert len(search_results) >= 1
            assert any(conv.conversation_id == conversation.conversation_id for conv in search_results)
            
            # Search by tag
            tag_results = await manager.search_conversations("user_test_001", "ml")
            assert len(tag_results) >= 1
            
            self._pass_test(test_name)
            
            # Test conversation summary generation
            test_name = "Conversation Summary Generation"
            self._start_test(test_name)
            
            summary = await manager.generate_conversation_summary(conversation.conversation_id)
            assert summary is not None
            assert summary.conversation_id == conversation.conversation_id
            assert len(summary.brief_summary) > 0
            assert len(summary.detailed_summary) > 0
            assert len(summary.key_points) > 0
            assert len(summary.topics_discussed) > 0
            assert "positive" in summary.sentiment_analysis
            assert summary.quality_score > 0
            
            self._pass_test(test_name)
            
            # Test analytics generation
            test_name = "Analytics Generation"
            self._start_test(test_name)
            
            analytics = await manager.get_conversation_analytics(conversation.conversation_id)
            assert analytics is not None
            assert analytics.conversation_id == conversation.conversation_id
            assert analytics.message_count == len(conversation.messages)
            assert analytics.total_tokens > 0
            assert analytics.engagement_score >= 0
            assert len(analytics.topic_distribution) > 0
            assert "user" in analytics.user_participation
            assert "assistant" in analytics.user_participation
            assert len(analytics.quality_metrics) > 0
            
            self._pass_test(test_name)
            
            # Test similar conversations
            test_name = "Similar Conversations"
            self._start_test(test_name)
            
            # Create another conversation for similarity testing
            similar_conv_data = {
                "title": "Deep Learning Research",
                "description": "Exploring deep learning techniques",
                "conversation_type": "research",
                "tags": ["ml", "deep-learning", "research"]
            }
            
            similar_conv = await manager.create_conversation("user_test_001", similar_conv_data)
            await manager.add_message(similar_conv.conversation_id, MessageRole.USER, "What are the latest advances in deep learning?")
            
            similar_conversations = await manager.get_similar_conversations(conversation.conversation_id, limit=5)
            # Should find the similar conversation we just created
            assert len(similar_conversations) >= 0  # May or may not find similar based on content
            
            self._pass_test(test_name)
            
        except Exception as e:
            self._fail_test(test_name if 'test_name' in locals() else "Search and Analytics", str(e))
    
    async def _test_performance(self):
        """Test system performance with various loads"""
        print("\n‚ö° Testing Performance...")
        
        try:
            # Test conversation creation performance
            test_name = "Conversation Creation Performance"
            self._start_test(test_name)
            
            start_time = time.time()
            
            # Create 50 conversations
            for i in range(50):
                conv_data = {
                    "title": f"Performance Test Conversation {i}",
                    "conversation_type": "general",
                    "tags": [f"perf-test-{i}"]
                }
                await self.test_manager.create_conversation(f"perf_user_{i % 5}", conv_data)
            
            creation_time = time.time() - start_time
            avg_creation_time = creation_time / 50
            
            # Performance should be reasonable (less than 10ms per conversation)
            assert avg_creation_time < 0.01, f"Conversation creation too slow: {avg_creation_time:.4f}s"
            
            self.results['performance_metrics']['conversation_creation'] = {
                'total_time': creation_time,
                'average_time': avg_creation_time,
                'conversations_created': 50
            }
            
            self._pass_test(test_name)
            
            # Test message processing performance
            test_name = "Message Processing Performance"
            self._start_test(test_name)
            
            # Create a conversation for message testing
            perf_conv_data = {"title": "Performance Test Messages"}
            perf_conv = await self.test_manager.create_conversation("perf_user_msg", perf_conv_data)
            
            start_time = time.time()
            
            # Add 200 messages
            for i in range(200):
                role = MessageRole.USER if i % 2 == 0 else MessageRole.ASSISTANT
                content = f"Performance test message {i} with realistic content for testing message processing speed and threading capabilities"
                await self.test_manager.add_message(perf_conv.conversation_id, role, content)
            
            processing_time = time.time() - start_time
            avg_processing_time = processing_time / 200
            
            # Performance should be reasonable (less than 5ms per message)
            assert avg_processing_time < 0.005, f"Message processing too slow: {avg_processing_time:.4f}s"
            
            self.results['performance_metrics']['message_processing'] = {
                'total_time': processing_time,
                'average_time': avg_processing_time,
                'messages_processed': 200
            }
            
            self._pass_test(test_name)
            
            # Test search performance
            test_name = "Search Performance"
            self._start_test(test_name)
            
            start_time = time.time()
            
            # Perform 20 searches
            for i in range(20):
                search_query = f"performance test {i % 5}"
                await self.test_manager.search_conversations("perf_user_msg", search_query)
            
            search_time = time.time() - start_time
            avg_search_time = search_time / 20
            
            # Search should be fast (less than 50ms per search)
            assert avg_search_time < 0.05, f"Search too slow: {avg_search_time:.4f}s"
            
            self.results['performance_metrics']['search'] = {
                'total_time': search_time,
                'average_time': avg_search_time,
                'searches_performed': 20
            }
            
            self._pass_test(test_name)
            
        except Exception as e:
            self._fail_test(test_name if 'test_name' in locals() else "Performance", str(e))
    
    async def _test_integration_scenarios(self):
        """Test complete integration scenarios"""
        print("\nüîó Testing Integration Scenarios...")
        
        try:
            # Test complete workflow scenario
            test_name = "Complete Workflow Integration"
            self._start_test(test_name)
            
            # Create a new manager for integration testing
            integration_manager = create_conversation_manager(self.config)
            
            # 1. Create conversation
            conv_data = {
                "title": "Software Development Project Discussion",
                "description": "Planning and implementing a web application",
                "conversation_type": "planning",
                "tags": ["software", "web-dev", "project"],
                "auto_threading": True
            }
            
            conversation = await integration_manager.create_conversation("integration_user", conv_data)
            
            # 2. Add realistic conversation flow
            conversation_flow = [
                (MessageRole.USER, "I'm starting a new web application project. What technology stack should I consider?"),
                (MessageRole.ASSISTANT, "For a modern web application, I'd recommend considering React or Vue.js for the frontend, Node.js or Python (Django/Flask) for the backend, and PostgreSQL or MongoDB for the database."),
                (MessageRole.USER, "I'm leaning towards React and Node.js. How should I structure the project?"),
                (MessageRole.ASSISTANT, "Great choice! I'd suggest a monorepo structure with separate frontend and backend folders, use Express.js for the API, and implement proper authentication and authorization."),
                (MessageRole.USER, "What about deployment and DevOps considerations?"),
                (MessageRole.ASSISTANT, "For deployment, consider using Docker containers with a CI/CD pipeline. You could deploy to AWS, Google Cloud, or Heroku. Set up automated testing and monitoring."),
                (MessageRole.USER, "How do I handle user authentication securely?"),
                (MessageRole.ASSISTANT, "Use JWT tokens with proper expiration, implement refresh token rotation, use HTTPS everywhere, and consider OAuth2 for social logins. Never store passwords in plain text.")
            ]
            
            for role, content in conversation_flow:
                await integration_manager.add_message(conversation.conversation_id, role, content)
            
            # 3. Create threads
            auth_messages = [msg.message_id for msg in conversation.messages[6:8]]  # Last 2 messages about auth
            auth_thread = await conversation.create_thread("Authentication & Security", auth_messages, "security")
            
            # 4. Generate summary and analytics
            summary = await integration_manager.generate_conversation_summary(conversation.conversation_id)
            analytics = await integration_manager.get_conversation_analytics(conversation.conversation_id)
            
            # 5. Export conversation
            export_data = await integration_manager.export_conversations("integration_user", format="dict")
            
            # 6. Verify all components work together
            assert len(conversation.messages) == 8
            assert len(conversation.threads) >= 1
            assert summary is not None
            assert analytics is not None
            assert export_data['conversation_count'] >= 1
            
            self._pass_test(test_name)
            
            # Test multi-user scenario
            test_name = "Multi-User Integration"
            self._start_test(test_name)
            
            users = ["user_a", "user_b", "user_c"]
            
            # Create conversations for multiple users
            for user in users:
                for i in range(3):
                    user_conv_data = {
                        "title": f"{user} Conversation {i+1}",
                        "conversation_type": ["general", "technical", "creative"][i],
                        "tags": [user, f"topic-{i}"]
                    }
                    
                    user_conv = await integration_manager.create_conversation(user, user_conv_data)
                    
                    # Add messages
                    await integration_manager.add_message(user_conv.conversation_id, MessageRole.USER, f"Message from {user}")
                    await integration_manager.add_message(user_conv.conversation_id, MessageRole.ASSISTANT, f"Response to {user}")
            
            # Verify system state
            system_analytics = await integration_manager.get_system_analytics()
            assert system_analytics['total_conversations'] >= 10  # 1 + 9 new
            assert system_analytics['total_messages'] >= 18  # 8 + 18 new
            
            # Test cross-user isolation
            user_a_convs = await integration_manager.get_user_conversations("user_a")
            user_b_convs = await integration_manager.get_user_conversations("user_b")
            
            assert len(user_a_convs) == 3
            assert len(user_b_convs) == 3
            assert all(conv.user_id == "user_a" for conv in user_a_convs)
            assert all(conv.user_id == "user_b" for conv in user_b_convs)
            
            self._pass_test(test_name)
            
        except Exception as e:
            self._fail_test(test_name if 'test_name' in locals() else "Integration Scenarios", str(e))
    
    async def _test_error_handling(self):
        """Test error handling and edge cases"""
        print("\nüõ°Ô∏è Testing Error Handling...")
        
        try:
            manager = self.test_manager
            
            # Test operations on non-existent conversation
            test_name = "Non-existent Conversation Handling"
            self._start_test(test_name)
            
            # Try to get non-existent conversation
            non_existent = await manager.get_conversation("non_existent_id")
            assert non_existent is None
            
            # Try to add message to non-existent conversation
            message = await manager.add_message("non_existent_id", MessageRole.USER, "Test")
            assert message is None
            
            # Try to delete non-existent conversation
            delete_success = await manager.delete_conversation("non_existent_id")
            assert delete_success is False
            
            self._pass_test(test_name)
            
            # Test invalid message operations
            test_name = "Invalid Message Operations"
            self._start_test(test_name)
            
            conversation = self.test_conversation
            
            # Try to edit non-existent message
            edit_success = await conversation.edit_message("non_existent_msg", "new content")
            assert edit_success is False
            
            # Try to delete non-existent message
            delete_success = await conversation.delete_message("non_existent_msg")
            assert delete_success is False
            
            self._pass_test(test_name)
            
            # Test invalid thread operations
            test_name = "Invalid Thread Operations"
            self._start_test(test_name)
            
            # Try to get messages from non-existent thread
            thread_messages = await conversation.get_thread_messages("non_existent_thread")
            assert len(thread_messages) == 0
            
            # Try to merge non-existent threads
            merge_success = await conversation.merge_threads("thread1", "thread2")
            assert merge_success is False
            
            self._pass_test(test_name)
            
            # Test empty conversation operations
            test_name = "Empty Conversation Operations"
            self._start_test(test_name)
            
            empty_conv = EnhancedConversation(
                user_id="empty_test_user",
                conversation_data={"title": "Empty Conversation"}
            )
            
            # Test operations on empty conversation
            search_results = await empty_conv.search_messages("anything")
            assert len(search_results) == 0
            
            summary = await empty_conv.generate_summary()
            assert summary is None
            
            analytics = await empty_conv.generate_analytics()
            assert analytics is None
            
            self._pass_test(test_name)
            
        except Exception as e:
            self._fail_test(test_name if 'test_name' in locals() else "Error Handling", str(e))
    
    def _start_test(self, test_name: str):
        """Start a test and update counters"""
        self.results['tests_run'] += 1
        print(f"  üß™ {test_name}...", end=" ")
    
    def _pass_test(self, test_name: str):
        """Mark test as passed"""
        self.results['tests_passed'] += 1
        self.results['functional_tests'][test_name] = 'PASSED'
        print("‚úÖ PASSED")
    
    def _fail_test(self, test_name: str, error: str):
        """Mark test as failed"""
        self.results['tests_failed'] += 1
        self.results['functional_tests'][test_name] = f'FAILED: {error}'
        self.results['errors'].append(f"{test_name}: {error}")
        print(f"‚ùå FAILED: {error}")
    
    def _generate_report(self):
        """Generate final validation report"""
        print("\n" + "="*60)
        print("üìä ADVANCED CONVERSATION MANAGEMENT VALIDATION REPORT")
        print("="*60)
        
        # Summary statistics
        total_tests = self.results['tests_run']
        passed_tests = self.results['tests_passed']
        failed_tests = self.results['tests_failed']
        success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        
        print(f"\nüìà SUMMARY STATISTICS:")
        print(f"Total Tests Run: {total_tests}")
        print(f"Tests Passed: {passed_tests}")
        print(f"Tests Failed: {failed_tests}")
        print(f"Success Rate: {success_rate:.1f}%")
        
        # Performance metrics
        if self.results['performance_metrics']:
            print(f"\n‚ö° PERFORMANCE METRICS:")
            for metric, data in self.results['performance_metrics'].items():
                print(f"{metric.replace('_', ' ').title()}:")
                if 'average_time' in data:
                    print(f"  - Average Time: {data['average_time']*1000:.2f}ms")
                if 'total_time' in data:
                    print(f"  - Total Time: {data['total_time']:.2f}s")
        
        # Test results breakdown
        print(f"\nüß™ DETAILED TEST RESULTS:")
        for test_name, result in self.results['functional_tests'].items():
            status_icon = "‚úÖ" if result == "PASSED" else "‚ùå"
            print(f"  {status_icon} {test_name}: {result}")
        
        # Errors
        if self.results['errors']:
            print(f"\n‚ùå ERRORS ENCOUNTERED:")
            for error in self.results['errors']:
                print(f"  - {error}")
        
        # Overall assessment
        print(f"\nüéØ OVERALL ASSESSMENT:")
        if success_rate >= 90:
            print("üü¢ EXCELLENT: Advanced Conversation Management system is working perfectly!")
            print("‚úÖ All core functionality operational")
            print("‚úÖ Performance benchmarks met")
            print("‚úÖ Error handling robust")
        elif success_rate >= 75:
            print("üü° GOOD: System is mostly functional with minor issues")
            print("‚ö†Ô∏è  Some non-critical features may need attention")
        elif success_rate >= 50:
            print("üü† FAIR: System has significant issues that need addressing")
            print("‚ö†Ô∏è  Core functionality works but reliability concerns exist")
        else:
            print("üî¥ POOR: System requires major fixes before deployment")
            print("‚ùå Critical functionality failures detected")
        
        # Recommendations
        print(f"\nüí° RECOMMENDATIONS:")
        if success_rate >= 90:
            print("‚úÖ System is ready for production deployment")
            print("‚úÖ Consider adding advanced features like ML-based threading")
            print("‚úÖ Implement monitoring and logging for production use")
        else:
            print("‚ö†Ô∏è  Address failing tests before deployment")
            print("‚ö†Ô∏è  Review error handling and edge cases")
            print("‚ö†Ô∏è  Consider additional testing with larger datasets")
        
        print("\n" + "="*60)
        print("üöÄ Advanced Conversation Management System Validation Complete!")
        print("="*60)

async def main():
    """Main validation function"""
    demo = ConversationValidationDemo()
    await demo.run_validation()

if __name__ == "__main__":
    # Check for required dependencies
    try:
        import numpy as np
        import sklearn
        print("üì¶ Required dependencies available")
    except ImportError as e:
        print(f"‚ö†Ô∏è  Missing dependency: {e}")
        print("Installing required packages...")
        import subprocess
        subprocess.run([sys.executable, "-m", "pip", "install", "numpy", "scikit-learn"], check=True)
        print("‚úÖ Dependencies installed")
    
    # Run the validation
    asyncio.run(main())
